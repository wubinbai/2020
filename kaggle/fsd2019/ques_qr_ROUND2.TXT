首先，想交流一下，我对FSD的理解，然后提出一些问题，关于data，metrics，model，coding上的。

我认为目前的技术大多是用图像识别的方法来处理音频，也就是说不是从音频的角度来分析。librosa能提取的特征很多，除了频谱外，其余大多都是2D矩阵形式，也有1Darray的。困难在于怎么运用这些特征，比方说怎么从一个matrix中算出一个或多个特征，我绞尽脑汁觉得很折腾，如果用的好，我认为一个很简单的模型就能识别出state of the art的准确率了。您觉得呢？而且，从音频的分析片段截取，我认为也不必像图像一样，因为音频是以秒为单位的，人能1秒内就分析是什么声音，音频应该可以从这个角度上，截取很段的一段进行分析，不一定需要3秒 5秒 甚至10秒，或许可以把每个音频分成若干个，分析，取平均？说到这点，我认为您的global feature是亮点也是关键，取了128段，每段都拿出了一些特征，我猜想恰是这些特征让网络”get“到了频率等等音频的特征，成功的得出结果？ 不过我觉得在global feature提取之前，应该也是可以用librosa trim一下剪掉前后的空白声音部分。补充一下，我认为可以把librosa的很多其他特征，加到这些global feature上面，虽然是矩阵和向量，用std max min这些最简单的， 没准会提升很多准确率？您试过这个吗？
补充：我用了1000个音乐wav文件做测试。（网上自己找的音乐分类文件10类）我用过了librosa的5-10个feature，用4层左右的神经网络可以预测60-70的准确率。脑洞大开，用个RandomForest可以非常快预测出百分之78正确率！这是初步的结果，准备“拍拍脑袋”加一些percentile向您的global feature一样哈哈，这个方法貌似很不错。


ANS:


在开始的一大段话。 特征不再多，在于差异性，在于所含信息是否有过大重叠。mel spectrogram已经涵盖音频的大部分信息了，没必要啥东西都调用一次。过分加入信息一致的特征，只会引入许多无用参数导致过拟合。


1s人的确能听懂。。。   但可惜nn不行。他泛化能力不够，音频片段稍微一遍他就觉得不一样，也可以说成数据量不足，我个人认为数据量扩的足够大，1s是可辨识的
d
# ROUND2：
我的想法是如果可以把每个音频文件裁剪成有具体含义的1-n段，n可以是>=2的任意一个数字。每一个作为一个sample，输入给模型，这样会不会很不错？
random clip。一直都有做，但这不能保证输入1s就不减性能。除了知道哪些是，还要知道哪些不是才有意义。
03.10 ANS:random clip我不是一直在做吗，仍然不够啊，不是你把输入缩短了，然后把一个数据剪成几份，数据集所含的信息就变多了。。你这是掩耳盗铃。


global feature涨了一个点我忘了？但不是决定性影响，trim这段去不去其实影响不大，都是常量，模型很容易区分出这部分没信息，因为每个特征这部分位置都一样，跟padding一个道理，conv可以从padding学习到图片的绝对位置，gru,conv1d也可以从文本的padding得知文本的长度。









除了上面没有序号的问题和想法，下面是带序号的：
1a 数据分为curated，noisy，test，听起来test和curated比较像，因此如果有一个比较好的算法，noisy这类嘈杂的声音是否可以不直接用，，但大多获奖的都用了noisy，是否是因为神经网络庞大本身的原因。

ANS1:



1a noisy主要是用作预训练。带有一定噪声的数据集训练出来的权重比随机初始化好很多。但并不能和curated进行混合训练，噪声相较curated太大。有domain adaptive的算法可以试试，不过这类算法实现逻辑复杂，训练奔溃超参较多，我很早之前玩过一些体验都很差，这个比赛就直接不浪费时间了

ROUND2：
那么，如果我有一个ok的模型（简单的比如RF，不一定用NN）+提取出了完美的、简单的的音频特征，理论上可以达到99%+的准确率吗？

03.10 ANS:正确的废话。。。这种特征还很容易得到，比如用nn训练完了，把它最后分类器前面pooling之后的512/1024维度的特征丢给树模型他也可以得到nn的分数，但这有啥意义。问题在于完美的，简单的特征你怎么得到呢？nn本身就是个特征抽取器，特征抽取+分类器，他干的就是把特征工程的活儿弄成调结构。你要加特征不引入新信息几乎是不可能涨分的，你的模型不能太差。tabular里由于没有一个很适当的结构，所以会常出现简单调整的树模型效果好于nn。并不代表非结构化数据也能这么容易。从引入的信息量上就有差距了。在不知道怎样提取所谓的完美特征的情况下，树接受几千维就很勉强了，nn一张图224*224*3你自己算算多少维度，树少接收了多少信息？不能增量式学习是树一个巨大的痛点。


1b 数据方面，第二个问题。有很多音频文件是多标签的，我统计了一下，有2个标签，3个标签，3、4、甚至5 6 个 都有 最多（6-7） 那么这些多标签的数据怎么处理呢？我本来有个可能是不成熟的想法，就是把每个文件复制到每一个标签的文件夹下面，这样一共有80个文件夹（左右），但是有多标签的怎么处理？？会被复制到多个文件夹下。按照这种办法，也只能分1个类，无法分多类。

ANS1:
1b 你没看代码吗。我直接输出80类sigmoid了

ROUND2:hi明白！sigmoid输出80个类的每个的概率（0-1）但是这里问题的意思是在80个标签中，除了（大概一半）的音频，有很多是有2个标签，3个标签，4个标签的，我统计了一下，有几百个2个标签，3个标签，4个标签的少一些，5-6个标签的基本只有个位数的音频文件。所以问题不是问80个标签类，而是每一个音频的prediction和real label是多标签，那么有两个问题。a.如何把多标签的label转换成数据？比如 1 0.5 0 0 0 0.3 0 0 （总共80个）代表一个音频文件是3个标签的？b.如果把每个文件都分到一个文件夹（80个一共），那么多标签文件怎么分呢？
03.10 ANS： a:问的是prediction转化为各个类吧，设定阈值然后分类啊。 B.为什么要把每个文件分到一个文件夹？他本来就属于多个类，你这不是矛盾吗？？？

ANS2:
说一下github fsd的readme
2 global pooling 的pixelshuffle 这个函数能简单解释一下吗？ + max pooling in time axes + ave pooling in mel axis这些在哪里体现？se block在model里有看到是squeeze and excite 请问这个网络的来源资源有吗？怎么想到的？为什么？l1 conv又是？是regularization 的 1 类吗 l1 l2 这些？ label smoothing是？（不好意思这些概念应该比较基本但是我都没用过或者现在还没有理解）

ANS1:

2. pixelShuffle直接查，超分里的一个结构，我理解起来是介于global pooling 和flatten的中间态。     se block查 senet。   label smooth也直接查，就是软化标签类似于概率形式不是非0即1的确定性，操作直接看我dataset的代码，知识蒸馏也是一种smooth。   l1 conv是啥我没写过这东西吧，你截图一下。

ROUND2:
se net查到了，作为初学者，您能不能给一点学习 se net的建议？是看博客，直接百度，还是看arxiv论文？（太花时间而且不一定看的懂）。还是简单理解模型图？又或者是需要掌握到什么程度？然后一步一步在来。

知识蒸馏？一开始以为打错字，搜索了一下，您怎么知道这么多啊！！！赶不上您的速度了如果不赶紧学，赶紧学也不一定赶得上啊！！！wt。。

l1 conv,抱歉，是打印出的错误，我查看了readme，发现是 1*1 conv，不过1*1的conv是什么数学含义？上知乎搜索了一下，1*1是说能改变dimension，up or down, depending on # filters。inception module常用。
03.10 ANS: 怎么看有啥好纠结的啊，觉得困难就中英结合啊。你总是不看英文的，那你怎么赶上最新的，总是落后于别人一两年有啥用，自己学会找重点抓重点看。se block这个10行代码就能写完的入门级结构有啥好纠结的，配着代码和他的解释看看完就结束了。1*1卷积就是用来压缩的，数学上1*1卷积就是个矩阵/全连接，用来升维度降维度。

3 mixup 就是FreeSound这个class里面定义的吗，generator每次生成一个batch的音频就会修改里面的数据，叫做mixup混合，音频增强augment？还有个问题，batch_y(-lm-lm+1) + lm 这个是我自己根据代码推算出来的，lm是0.0几，一个很小的数字，那么这里意思是吧0变成0.0几，把1变成0.99 类似这样吗？什么原因？

ANS1:

这个就是label smooth  mixup是起源于图像的数据增强，声音也是线性叠加后可区分的，所以我认为这里也可以使用

0
5

4 3TTA的3的意思？test time augmentation 在哪个文件有代码？我好像没找到。
3TTA 就是你说的意思。这个在训练的时候我好像在计算验证集分数的时候用了，你可以看看，就是补padding的位置不一样
ROUND2:

3TTA的3是三个的意思吗？？？？？？
另外，没有在utils.py的FreeSound class里找到augment test这些？
03.10 ANS:是的。augment test怎么会写在dataloader里，肯定是预测的时候做啊，你应该在predict和train里面找

5 stacker 在 ensemble文件里。LocallyConnected1D怎么理解？其实我很多keras的层，类似这样的都不太理解。要怎么去理解呢？ 更别说下面这个： 1.6 和 0.5 完全不知道哪里来的？x = Lambda(lambda x: (x-1.6))(x) 还有一个 （x+1 ）*0.5 实在不理解为什么。

ANS:

5. locallyconnected1d就是conv1d但是权重不共享只有局部连接，这样可以实现每个类学习一个集成权重。1.6和0.5单纯是缩放一下分数调的。  (x+1)*0.5是因为激活函数是tanh要把他缩放到01之间再用logloss

ROUND2:
感谢！（x+1）0.5理解了-1,1 -> 0,1 1.6和 0.5怎么理解？为什么不是1.2 0.7之类其他数字？
03.10 ANS:我都说了啊，调的啊，口述过一次，上一次写给你一次，这次再次强调调的不要问了。缩放值手调一下很困难吗，就两个参数

说完了readme，下面是具体代码问题。

6 关于模型model.py里定义的十几个def model 和 conv block 之类的，这些有没有一些总结呢？我看起来比较吃力，如果有一些注释什么的可能会更好。可能一方面也是我经验不够。能否简单介绍一下呢？或许顺便可以放进github里的Q&A环节哈哈。se max3exam v1mix 这些都是些什么？抱歉！我真的不懂。您应该能解释的清楚！

ANS1:

6. 这些model就是几种block的排列组合罢了，用不用se block 用不用multi scale. 等等。  名字你就别纠结了v1就是version1 max3是axis第三个轴  名字随便起的。没有啥特殊意义

ROUND2:
MSC r4 1.0 是？
03.10 ANS：1.0 channel倍数，msc r4结构。名字的问题我不想回答了有啥意义吗。。。你自己看代码啊，随便起个名字这么注重干啥，重要的不是配置吗，我起个杨超越你也要缠着我问？

7 metrics 方面。您用的是skleran的  label_ranking_average_precision 这样的。在kernel上面和第一名的代码使用的是google colab上的lwlrap，好长啊！我看的头晕。整整可以打印2面的A4纸。所以我是想问一下到底用sklearn可以不，为什么还需要google上面的？我的理解是sklearn的版本是简化版本的？那么lwlrap到底和sklearn有上面不一样？我试过sklearn的这个，就是按照预测的排名。0的话不考虑分数。取平均值。直接用这个就完美了啊？

ANS1:
lwlrap就是lrap对每个类用不同权重我印象中是这样的。但是我记得那个题每个权重都是1。这里等价。

ROUND2:
再次查看了官网，确实是跟权重有关系，但是是用一样的权重哦。关键词是 label上的average 不是item上的average。也就是说预测一个音频，比如预测出了3个类，那么这3个没有先后关系。权重一样。如此看来，您用sklearn的label_ranking_precision_score是不恰当的吗？哈哈，因为sklearn是有考虑先后关系的哦。我试过了。那么就是要用google colab的代码？其实，我问这个问题的最开始还没想过您用的metric可能会有这个问题，我是想问，这个metric到底该不该用30-60分钟去读代码。太费时间了～

03.10 ANS：不用，不就一个无阈值的排序指标吗，一个大方向小领域几十个，你看不完指标的。常见的记住就好了。


The novel "label-weighted" part means that the overall score is the average over all the labels in the test set, where each label receives equal weight (by contrast, plain lrap gives each test item equal weight, thereby discounting the contribution of individual labels when they appear on the same item as multiple other labels). 

ANS2:


8 关于kapre，想问若干个问题，您是如何搜索或知道这个的？在time_frequency.py当中您引用了2个class Melspectrogram 和 AdditiveNoise 请问您是直接用起来吗，是否有理解里面的各种参数和内部的算法，需要知道哪些就足够用了呢？

ANS1:
8. 为什么知道。花一天时间调研呗。看过实现，因为我要知道每个参数的具体意义，否则不好调，其实代码没多少，call的部分就是矩阵乘法，傅立叶变换用卷积实现外加一些乱七八糟的缩放而已逻辑很简单。你看多了就习惯了。


9关于kernel competition submit，目前比赛结束后还可以submit吗？我记得我曾经试着submit 后结果是0.0 不知道什么意思。

ANS:
9. 我不清楚，我记得非kernel赛是可以的        

10 另一方面，kernel competition的submit总的来说，是不是把深度网络的h5文件，npy数据文件保存起来，上传到kernel上，进行进一步的最后预测吗？还有如果要submit您的submission是要怎么写notebook代码提交呢？是不是直接用ensemble.py以及相关的文件上传呢？
ANS:
10. kaggle上开一个dataset 权重上传，开一个notebook 引入这个dataset，然后把预测推断的代码写到notebook里，然后最后结果存成submission.csv，然后点commit，等他跑完点到他弹出的链接，拉到最下面的输出文件位置，点submit submission

ROUND2: 我弄了一下，网络比较不行，就是 upload data吗？npy和h5文件这样。是不是在大陆都需要翻墙才ok？

万分感谢了！实际上还有不少问题没问，不能一口吃成胖子，先问一些消化一下吧！感谢钱老师！
03.10 ANS：早些时间不用翻墙，后来好像一直要翻墙了

