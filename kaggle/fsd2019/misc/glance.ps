%!PS-Adobe-3.0
%%Title: glance.txt
%%For: wb
%%Creator: VIM - Vi IMproved 8.0 (2016 Sep 12)
%%CreationDate: Wed Feb 26 11:19:56 2020
%%DocumentData: Clean8Bit
%%Orientation: Portrait
%%Pages: (atend)
%%PageOrder: Ascend
%%BoundingBox: 59 45 559 800
%%DocumentMedia: A4 595 842 0 () ()
%%DocumentNeededResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%DocumentSuppliedResources: procset VIM-Prolog 1.4 1
%%+ encoding VIM-latin1 1.0 0
%%Requirements: duplex collate
%%EndComments
%%BeginDefaults
%%PageResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%PageMedia: A4
%%EndDefaults
%%BeginProlog
%%BeginResource: procset VIM-Prolog
%%BeginDocument: /usr/share/vim/vim80/print/prolog.ps
%!PS-Adobe-3.0 Resource-ProcSet
%%Title: VIM-Prolog
%%Version: 1.4 1
%%EndComments
% Editing of this file is NOT RECOMMENDED.  You run a very good risk of causing
% all PostScript printing from VIM failing if you do.  PostScript is not called
% a write-only language for nothing!
/packedarray where not{userdict begin/setpacking/pop load def/currentpacking
false def end}{pop}ifelse/CP currentpacking def true setpacking
/bd{bind def}bind def/ld{load def}bd/ed{exch def}bd/d/def ld
/db{dict begin}bd/cde{currentdict end}bd
/T true d/F false d
/SO null d/sv{/SO save d}bd/re{SO restore}bd
/L2 systemdict/languagelevel 2 copy known{get exec}{pop pop 1}ifelse 2 ge d
/m/moveto ld/s/show ld /ms{m s}bd /g/setgray ld/r/setrgbcolor ld/sp{showpage}bd
/gs/gsave ld/gr/grestore ld/cp/currentpoint ld
/ul{gs UW setlinewidth cp UO add 2 copy newpath m 3 1 roll add exch lineto
stroke gr}bd
/bg{gs r cp BO add 4 -2 roll rectfill gr}bd
/sl{90 rotate 0 exch translate}bd
L2{
/sspd{mark exch{setpagedevice}stopped cleartomark}bd
/nc{1 db/NumCopies ed cde sspd}bd
/sps{3 db/Orientation ed[3 1 roll]/PageSize ed/ImagingBBox null d cde sspd}bd
/dt{2 db/Tumble ed/Duplex ed cde sspd}bd
/c{1 db/Collate ed cde sspd}bd
}{
/nc{/#copies ed}bd
/sps{statusdict/setpage get exec}bd
/dt{statusdict/settumble 2 copy known{get exec}{pop pop pop}ifelse
statusdict/setduplexmode 2 copy known{get exec}{pop pop pop}ifelse}bd
/c{pop}bd
}ifelse
/ffs{findfont exch scalefont d}bd/sf{setfont}bd
/ref{1 db findfont dup maxlength dict/NFD ed{exch dup/FID ne{exch NFD 3 1 roll
put}{pop pop}ifelse}forall/Encoding findresource dup length 256 eq{NFD/Encoding
3 -1 roll put}{pop}ifelse NFD dup/FontType get 3 ne{/CharStrings}{/CharProcs}
ifelse 2 copy known{2 copy get dup maxlength dict copy[/questiondown/space]{2
copy known{2 copy get 2 index/.notdef 3 -1 roll put pop exit}if pop}forall put
}{pop pop}ifelse dup NFD/FontName 3 -1 roll put NFD definefont pop end}bd
CP setpacking
(\004)cvn{}bd
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%BeginResource: encoding VIM-latin1
%%BeginDocument: /usr/share/vim/vim80/print/latin1.ps
%!PS-Adobe-3.0 Resource-Encoding
%%Title: VIM-latin1
%%Version: 1.0 0
%%EndComments
/VIM-latin1[
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclam /quotedbl /numbersign /dollar /percent /ampersand /quotesingle
/parenleft /parenright /asterisk /plus /comma /minus /period /slash
/zero /one /two /three /four /five /six /seven
/eight /nine /colon /semicolon /less /equal /greater /question
/at /A /B /C /D /E /F /G
/H /I /J /K /L /M /N /O
/P /Q /R /S /T /U /V /W
/X /Y /Z /bracketleft /backslash /bracketright /asciicircum /underscore
/grave /a /b /c /d /e /f /g
/h /i /j /k /l /m /n /o
/p /q /r /s /t /u /v /w
/x /y /z /braceleft /bar /braceright /asciitilde /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclamdown /cent /sterling /currency /yen /brokenbar /section
/dieresis /copyright /ordfeminine /guillemotleft /logicalnot /hyphen /registered /macron
/degree /plusminus /twosuperior /threesuperior /acute /mu /paragraph /periodcentered
/cedilla /onesuperior /ordmasculine /guillemotright /onequarter /onehalf /threequarters /questiondown
/Agrave /Aacute /Acircumflex /Atilde /Adieresis /Aring /AE /Ccedilla
/Egrave /Eacute /Ecircumflex /Edieresis /Igrave /Iacute /Icircumflex /Idieresis
/Eth /Ntilde /Ograve /Oacute /Ocircumflex /Otilde /Odieresis /multiply
/Oslash /Ugrave /Uacute /Ucircumflex /Udieresis /Yacute /Thorn /germandbls
/agrave /aacute /acircumflex /atilde /adieresis /aring /ae /ccedilla
/egrave /eacute /ecircumflex /edieresis /igrave /iacute /icircumflex /idieresis
/eth /ntilde /ograve /oacute /ocircumflex /otilde /odieresis /divide
/oslash /ugrave /uacute /ucircumflex /udieresis /yacute /thorn /ydieresis]
/Encoding defineresource pop
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%EndProlog
%%BeginSetup
595 842 0 sps
1 nc
T F dt
T c
%%IncludeResource: font Courier
/_F0 /VIM-latin1 /Courier ref
/F0 13 /_F0 ffs
%%IncludeResource: font Courier-Bold
/_F1 /VIM-latin1 /Courier-Bold ref
/F1 13 /_F1 ffs
%%IncludeResource: font Courier-Oblique
/_F2 /VIM-latin1 /Courier-Oblique ref
/F2 13 /_F2 ffs
%%IncludeResource: font Courier-BoldOblique
/_F3 /VIM-latin1 /Courier-BoldOblique ref
/F3 13 /_F3 ffs
/UO -1.3 d
/UW 0.65 d
/BO -3.25 d
%%EndSetup
%%Page: 1 1
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 1)59.5 790.15 ms
F0 sf
(A glance into competitive data science: the best practices for c)59.5 764.15 ms
(omputer vision)59.5 751.15 ms
(How several techniques can dramatically improve the performance )59.5 738.15 ms
(of your computer vision models¿)59.5 725.15 ms
(Pierre-Antoine Bannier)59.5 712.15 ms
(Jun 13, 2019 · 11 min read)59.5 699.15 ms
(Introduction)59.5 686.15 ms
(Since the Freesound Audio Tagging 2019 competition is coming to )59.5 673.15 ms
(a close, I have decided to write an article about the best pract)59.5 660.15 ms
(ices and techniques for building a robust computer vision model,)59.5 647.15 ms
( that I¿ve learnt during my first research competition. Furtherm)59.5 634.15 ms
(ore, it is a way for me to lay my ideas on paper in order to hav)59.5 621.15 ms
(e a structured and clear overview of the techniques I¿ve used: t)59.5 608.15 ms
(he ones that worked well, as well as the ones that didn¿t yield )59.5 595.15 ms
(a significant improvement in my test score.)59.5 582.15 ms
(As a student of the Fast.ai course, I¿m still at the very start )59.5 556.15 ms
(of my learning journey, hence some remarks or techniques that co)59.5 543.15 ms
(uld seem obvious for the most experienced of you.)59.5 530.15 ms
(As always, I strongly encourage you to correct me, to ask me pre)59.5 504.15 ms
(cisions on a specific point if you don¿t get it or if it is uncl)59.5 491.15 ms
(ear, and to add some remarks in the comment section!)59.5 478.15 ms
(    The most critical lesson that I get from this competition is)59.5 452.15 ms
( that building robust models is an empirical process. Competing )59.5 439.15 ms
(helps develop an intuition for what might work or not.)59.5 426.15 ms
(To give you a bit of context, the competition is about tagging \()59.5 400.15 ms
(classifying\) sounds \(cat, waterfalls, musical instruments¿\). We )59.5 387.15 ms
(were given two datasets: a curated one with clearly-audible soun)59.5 374.15 ms
(ds \(4970 entries\) and a noisy one with a sound and some noises i)59.5 361.15 ms
(n the background \(20000-odd entries\). Note that each data entry )59.5 348.15 ms
(has multiple labels. Both datasets were labelled. The main chall)59.5 335.15 ms
(enge of the competition \(identified by the vast majority of the )59.5 322.15 ms
(participants\) was to correctly use the noisy dataset to enhance )59.5 309.15 ms
(the performance on the curated data.)59.5 296.15 ms
(We were evaluated with respect to a custom metric: the label-wei)59.5 270.15 ms
(ghted label-ranking average precision also abbreviated lwlrap. T)59.5 257.15 ms
(o give a scale, the top 1% achieved a lwlrap score of 0.76, whil)59.5 244.15 ms
(e a bronze medal \(top 12% roughly\) was awarded with a score of 0)59.5 231.15 ms
(.695 or above. My final score during stage 1 was 0.686, which pu)59.5 218.15 ms
(t me in the top 15%.)59.5 205.15 ms
(Fast Fourier Transforms and melspectrograms: how to feed sounds )59.5 192.15 ms
(into a CNN?)59.5 179.15 ms
(Since the beginning of the article, you might find it weird that)59.5 153.15 ms
( I speak about computer vision and sounds at the same time. Inde)59.5 140.15 ms
(ed, a sound is a time-based signal composed of multiple samples.)59.5 127.15 ms
( At first, we could think that we can feed a sound into a CNN by)59.5 114.15 ms
( applying 1D convolutions or into a LSTM-based model. However, b)59.5 101.15 ms
(oth techniques did not yield convincing results, probably due to)59.5 88.15 ms
( the loss of information incurred by feeding a raw signal into a)59.5 75.15 ms
( model. Feeding a raw signal leads to a significant loss of info)59.5 62.15 ms
(rmation namely, frequency, phase, amplitude. After some experime)59.5 49.15 ms
re sp
%%PageTrailer
%%Page: 2 2
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 2)59.5 790.15 ms
F0 sf
(nts, both models did not yield a lwlrap over 0.5. Quite disappoi)59.5 764.15 ms
(nting¿)59.5 751.15 ms
(As a rule of thumb for audio classification, we usually transfor)59.5 725.15 ms
(m the sounds into a much more comprehensive 2D representation \(a)59.5 712.15 ms
(n image\) that we feed into a CNN. This representation can be a M)59.5 699.15 ms
(FCC, a Chroma, a CQT-Transform, but it is often a mel-spectrogra)59.5 686.15 ms
(m.)59.5 673.15 ms
(Mel-spectogram of a signal plotted with Matplotlib)59.5 660.15 ms
(To understand how a mel-spectrogram is generated, we first need )59.5 634.15 ms
(to understand what a Fourier transform does to our signal. The F)59.5 621.15 ms
(ast Fourier Transform \(a modified algorithm with a lower complex)59.5 608.15 ms
(ity o\(nlogn\) than the original version o\(n2\)\) converts a sound s)59.5 595.15 ms
(ignal from its original time domain to a representation in the f)59.5 582.15 ms
(requency domain.)59.5 569.15 ms
(Then we apply a series of transformations to finally get the mel)59.5 543.15 ms
(-spectogram representation.)59.5 530.15 ms
(In order to perform this series of calculations, you can directl)59.5 504.15 ms
(y use the librosa library that has various functions to perform )59.5 491.15 ms
(audio feature analysis.)59.5 478.15 ms
(Additional readings:)59.5 452.15 ms
(    How to convert sounds into images in Python \(a kernel by Dai)59.5 426.15 ms
(sukelab\): https://www.kaggle.com/daisukelab/creating-fat2019-pre)59.5 413.15 ms
(processed-data)59.5 400.15 ms
(    A set of notebooks for audio features analysis: https://musi)59.5 387.15 ms
(cinformationretrieval.com/)59.5 374.15 ms
(    An introduction to the librosa library in Python: https://to)59.5 361.15 ms
(wardsdatascience.com/audio-classification-using-fastai-and-on-th)59.5 348.15 ms
(e-fly-frequency-transforms-4dbe1b540f89)59.5 335.15 ms
(Mixup: a must-have to achieve state-of-the-art results in comput)59.5 309.15 ms
(er vision)59.5 296.15 ms
(Simply put, Mixup is a data augmentation technique that creates )59.5 270.15 ms
(new data entries from a linear relationship between two existing)59.5 257.15 ms
( data entries. We can sum it up with this formula. ¿ are tensors)59.5 244.15 ms
( that represent images, while ¿ are weights.)59.5 231.15 ms
(The same transformation is applied to the target:)59.5 205.15 ms
(It is no more than a weighted average of two-existing data sampl)59.5 179.15 ms
(es. For instance, we could choose ¿ = 0.7. If ¿1 represents a do)59.5 166.15 ms
(g and ¿2 a cat, ¿new will represent something between a dog and )59.5 153.15 ms
(a cat, nearer from the dog than the cat. If you look at the imag)59.5 140.15 ms
(e associated to ¿new, it may not make a lot of sense for you, bu)59.5 127.15 ms
(t for the computer it clearly sees a dog, hence augmenting the d)59.5 114.15 ms
(og image dataset.)59.5 101.15 ms
(Representation of a new data sample using Mixup \(credits: Fast.a)59.5 88.15 ms
(i\))59.5 75.15 ms
(As you can see it can act as a powerful data augmentation techni)59.5 49.15 ms
re sp
%%PageTrailer
%%Page: 3 3
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 3)59.5 790.15 ms
F0 sf
(que by creating new data from other existing pieces of data. It )59.5 764.15 ms
(is particularly useful when you have to deal with class imbalanc)59.5 751.15 ms
(e. It was the case during this competition \(where some labels ha)59.5 738.15 ms
(d very few occurrences, while others had a lot more\). This singl)59.5 725.15 ms
(e technique helped me break the 0.6 lwlrap barrier, from 0.57 to)59.5 712.15 ms
( 0.65 on leaderboard \(combined with other techniques listed belo)59.5 699.15 ms
(w\).)59.5 686.15 ms
(Additional readings:)59.5 660.15 ms
(    Mixup original research paper: https://arxiv.org/abs/1710.09)59.5 634.15 ms
(412)59.5 621.15 ms
(    Fast.ai documentation on Mixup : https://docs.fast.ai/callba)59.5 608.15 ms
(cks.mixup.html)59.5 595.15 ms
(Training Time Augmentation \(TTA\): scraping ranks in the leaderbo)59.5 569.15 ms
(ard)59.5 556.15 ms
(Training Time Augmentation \(TTA\) is a form of data augmentation )59.5 530.15 ms
(technique used during inference. Results from TTA are obtained b)59.5 517.15 ms
(y computing the weighted average of standard predictions and pre)59.5 504.15 ms
(dictions made on your dataset after applying data augmentation t)59.5 491.15 ms
(echniques. Unsurprisingly, the equation looks very similar to th)59.5 478.15 ms
(e Mixup¿s:)59.5 465.15 ms
(By default, in fast.ai the beta coefficient is set at 0.4.)59.5 439.15 ms
(Note that in Fast.ai, TTA computes log-probabilities \(hence the )59.5 413.15 ms
(negative numbers\). To pass from log-probabilities to ¿standard¿ )59.5 400.15 ms
(probabilities \(between 0 and 1\), just compute the exponential of)59.5 387.15 ms
( the probabilities.)59.5 374.15 ms
(The only issue that you can face is how long the model takes to )59.5 348.15 ms
(compute the predictions. Especially if you have tight time const)59.5 335.15 ms
(raints for the execution of your model, TTA might not be a good )59.5 322.15 ms
(choice.)59.5 309.15 ms
(As for the competition, it made me jump \(with Mixup\) from 0.57 o)59.5 283.15 ms
(n leaderboard to 0.65.)59.5 270.15 ms
(Transfer, semi-supervised learning and pseudo labelling)59.5 257.15 ms
(Transfer learning consists in pre-training your model with a dat)59.5 231.15 ms
(aset and then training it with the dataset that is the closest t)59.5 218.15 ms
(o what you want to predict. It is a technique that allows a fast)59.5 205.15 ms
(er training and a steadier convergence to the loss optimum. It i)59.5 192.15 ms
(s now a standard in the industry, be it for computer vision or N)59.5 179.15 ms
(LP with ULMFiT-based models and BERT.)59.5 166.15 ms
(For this competition, I chose to first pre-train my model on the)59.5 140.15 ms
( noisy dataset to train my model on the curated dataset eventual)59.5 127.15 ms
(ly. On my local machine, my lwlrap jumped from 0.81 to 0.83. Let)59.5 114.15 ms
(¿s recall that the competition did not allow pre-trained models.)59.5 101.15 ms
(The second technique I tried was semi-supervised learning. It is)59.5 75.15 ms
( particularly useful if you have a lot of unlabeled data. It hel)59.5 62.15 ms
(ps the model map the data distribution and allows a faster conve)59.5 49.15 ms
re sp
%%PageTrailer
%%Page: 4 4
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 4)59.5 790.15 ms
F0 sf
(rgence.)59.5 764.15 ms
(    You better take one week to label additional data than tryin)59.5 738.15 ms
(g to create a model that would perfectly take advantage of the u)59.5 725.15 ms
(nlabeled data.)59.5 712.15 ms
(I chose one particular type of semi-supervised learning: pseudo-)59.5 686.15 ms
(labelling the noisy data. In this competition, we had a large nu)59.5 673.15 ms
(mber of noisy data. Rather than using the existing labels, I tra)59.5 660.15 ms
(ined a model on curated data, then used this model to label my n)59.5 647.15 ms
(oisy data. Eventually, by combining the curated data with the ne)59.5 634.15 ms
(wly-labelled noisy data, I re-trained my model. Although, it did)59.5 621.15 ms
( not improve significantly the performance due to too much diffe)59.5 608.15 ms
(rence between the curated data distribution and the noisy one, i)59.5 595.15 ms
(n an ensemble model, the performance increased.)59.5 582.15 ms
(I may conclude by stating that you better take one week to label)59.5 556.15 ms
( additional data than trying to create a model that would perfec)59.5 543.15 ms
(tly take advantage of the unlabeled data. Semi-supervised learni)59.5 530.15 ms
(ng techniques are typically suited when you have large amount of)59.5 517.15 ms
( spare data.)59.5 504.15 ms
(Additional reading:)59.5 478.15 ms
(    A comprehensive explanation of pseudo labelling: https://www)59.5 452.15 ms
(.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervis)59.5 439.15 ms
(ed-learning-technique/)59.5 426.15 ms
(K-Fold Cross Validation and bootstrap aggregating: achieving mor)59.5 400.15 ms
(e stable results during inference)59.5 387.15 ms
(Since K-Fold CV is not particularly highlighted in the fast.ai c)59.5 361.15 ms
(ourse, I haven¿t really used it although it is a standard in the)59.5 348.15 ms
( industry. Let me quickly recall the definition of K-Fold valida)59.5 335.15 ms
(tion: it is a technique whereby a dataset is divided into K-Fold)59.5 322.15 ms
(, a model is trained on K-1 folds and validated on the remaining)59.5 309.15 ms
( fold. Obviously, K models are generated since each model has a )59.5 296.15 ms
(different validation set. This leads to more accurate and consis)59.5 283.15 ms
(tent performance assessment.)59.5 270.15 ms
(A 5-fold cross-validation scheme)59.5 257.15 ms
(But beyond being a validation technique, K-Fold CV can be used w)59.5 231.15 ms
(ithin an ensemble model \(the fancy word for that is bootstrap ag)59.5 218.15 ms
(gregating\). This word hides pretty straightforward and simple te)59.5 205.15 ms
(chniques where for instance you compute the average of all the p)59.5 192.15 ms
(redictions on your K folds. This ensemble technique usually yiel)59.5 179.15 ms
(ds better performance since the variance of the overall model is)59.5 166.15 ms
( dramatically reduced.)59.5 153.15 ms
(Ensembling technique: the key to enter the top 5%)59.5 140.15 ms
(My previous paragraph introduced a key notion for competitive da)59.5 114.15 ms
(ta science and broadly speaking for creating more accurate model)59.5 101.15 ms
(s: the concept of ensembling. Simply put, ensembling is a techni)59.5 88.15 ms
(que where several models are put together to gain stability in y)59.5 75.15 ms
(our predictions and precision.)59.5 62.15 ms
re sp
%%PageTrailer
%%Page: 5 5
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 5)59.5 790.15 ms
F0 sf
(To achieve a highly-performant ensemble model, you need to check)59.5 764.15 ms
( the correlation between all your models. The less correlated, t)59.5 751.15 ms
(he better. In order to do so, you compute the Pearson correlatio)59.5 738.15 ms
(n coefficient:)59.5 725.15 ms
(Where ¿ is the standard deviation of the statistical series, cov)59.5 699.15 ms
(\(X,Y\) the covariance of the statistical series X and Y.)59.5 686.15 ms
(    By combining a simple baseline model with only curated data,)59.5 660.15 ms
( a transfer learning model and a pseudo-labelling model, I was a)59.5 647.15 ms
(ble to achieve my highest score on the leaderboard: 0.686.)59.5 634.15 ms
(To make it clearer, the statistical series X and Y are the predi)59.5 608.15 ms
(ctions of your models. For each model that you create, you can c)59.5 595.15 ms
(ompute the Pearson correlation coefficient between each other, a)59.5 582.15 ms
(nd discard the models that are highly correlated.)59.5 569.15 ms
(In this competition, X and Y would be matrices that contain the )59.5 543.15 ms
(probabilities of belonging to one of the 80 classes for every da)59.5 530.15 ms
(ta sample.)59.5 517.15 ms
(As for the competition, the ensembling technique clearly gave me)59.5 491.15 ms
( the opportunity to come close to a bronze medal. By combining a)59.5 478.15 ms
( simple baseline model with only curated data, a transfer learni)59.5 465.15 ms
(ng model and a pseudo-labelling model, I was able to achieve my )59.5 452.15 ms
(highest score on the leaderboard: 0.686.)59.5 439.15 ms
(Additional reading:)59.5 413.15 ms
(    A comprehensive guide for ensembling technique, from averagi)59.5 387.15 ms
(ng to stacked generalization: https://mlwave.com/kaggle-ensembli)59.5 374.15 ms
(ng-guide/)59.5 361.15 ms
(Where to go from here?)59.5 335.15 ms
(It is now time to adopt a critical point of view on my performan)59.5 309.15 ms
(ce. Since I did not earn a medal, there are a lot of things to I)59.5 296.15 ms
( could have improved. I am going to force myself to think about )59.5 283.15 ms
(things that I could have done differently, or in addition to wha)59.5 270.15 ms
(t I have already done.)59.5 257.15 ms
(Know your data)59.5 244.15 ms
(Probably my most critical error consisted in rushing too fast to)59.5 218.15 ms
( build a model, instead of first trying to understand the data d)59.5 205.15 ms
(istribution and the kind of noise in the noisy dataset. It would)59.5 192.15 ms
( have allowed me to better understand the difficulty of predicti)59.5 179.15 ms
(ng a label and to read more relevant research papers to remove o)59.5 166.15 ms
(r attenuate the noise on the tracks.)59.5 153.15 ms
(Read research papers)59.5 140.15 ms
(This one is more of a reminder than an actual critic. I discover)59.5 114.15 ms
(ed how capital reading research papers was to apply techniques t)59.5 101.15 ms
(hat lead to state-of-the-art results. With the democratization o)59.5 88.15 ms
(f AI thanks to MOOC such as fast.ai course \(thanks again Jeremy )59.5 75.15 ms
(Howard, Rachel Thomas and the fantastic team behind the project\))59.5 62.15 ms
(, more and more people have access to powerful machine learning )59.5 49.15 ms
re sp
%%PageTrailer
%%Page: 6 6
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 6)59.5 790.15 ms
F0 sf
(tools that bring them closer to state-of-the-art results. Readin)59.5 764.15 ms
(g research papers and being able to implement some techniques de)59.5 751.15 ms
(scribed is an invaluable perk since it differentiates you from t)59.5 738.15 ms
(he competition. Few people are willing to take the time to read )59.5 725.15 ms
(it and even fewer to implement a technique.)59.5 712.15 ms
(One of the main objectives that I set for myself is being comfor)59.5 686.15 ms
(table enough with Fast.ai and its underlying framework PyTorch t)59.5 673.15 ms
(o implement and integrate my own snippets of code to the library)59.5 660.15 ms
(. For instance, I stumbled across this research paper https://ar)59.5 647.15 ms
(xiv.org/abs/1905.02249 which seems to be quite efficient since i)59.5 634.15 ms
(t is stated that MixMatch can reduce by a factor of 4 the error )59.5 621.15 ms
(rate. However after multiple attempts, I am not yet able to impl)59.5 608.15 ms
(ement it.)59.5 595.15 ms
(Using more data channels?)59.5 582.15 ms
(We¿ve talked previously about mel-spectograms and how they were )59.5 556.15 ms
(created. But other audio representations can be created namely, )59.5 543.15 ms
(Chroma, Mel Frequency Cepstral Coefficients \(MFCC\), Constant-Q T)59.5 530.15 ms
(ransform to name but a few. All these representations emphasize )59.5 517.15 ms
(on different aspects of an audio signal: one might explore the a)59.5 504.15 ms
(mplitude while the other the phase or the frequency. I was not a)59.5 491.15 ms
(ble to build an accurate enough model that would learn from the )59.5 478.15 ms
(phase for instance. I strongly believe that it was a key of the )59.5 465.15 ms
(competition since it adds more information to the mel-spectogram)59.5 452.15 ms
( models.)59.5 439.15 ms
(More complex ensembling techniques: weighted average, stacked ge)59.5 426.15 ms
(neralization?)59.5 413.15 ms
(While using an ensemble technique, I did not combine my models i)59.5 387.15 ms
(n a complex way. I merely computed the mean of all my prediction)59.5 374.15 ms
(s. I could have tried to fine-tune my model by choosing adequate)59.5 361.15 ms
( weights, hence creating a weighted average for my predictions.)59.5 348.15 ms
(I could have even tried to use a neural network that takes as an)59.5 322.15 ms
( input all the predictions from my different models and which tr)59.5 309.15 ms
(ies to detect non-linear patterns between the different predicti)59.5 296.15 ms
(ons. One challenge was data limitation. We only had 4970 data sa)59.5 283.15 ms
(mples in the curated dataset, and removing 1000 data samples wou)59.5 270.15 ms
(ld have been counterproductive, since 4970 was already a low num)59.5 257.15 ms
(ber.)59.5 244.15 ms
(I did not try to train my model on the noisy dataset, since the )59.5 218.15 ms
(distribution was too far from the testset¿s.)59.5 205.15 ms
(Conclusion)59.5 192.15 ms
(I¿m going to be short for the conclusion, since the article is a)59.5 166.15 ms
(lready quite long \(congrats and thanks if you are still here\). T)59.5 153.15 ms
(he most critical lesson that I get from this competition is that)59.5 140.15 ms
( building robust models is an empirical process. You try, you fa)59.5 127.15 ms
(il, you think, and you correct. You have to try a lot of things )59.5 114.15 ms
(in order to become good at it. Competing helps develop an intuit)59.5 101.15 ms
(ion for what might work and what might not.)59.5 88.15 ms
(I hope you liked this article. Again, don¿t hesitate to correct )59.5 62.15 ms
(me if I am wrong on certain points or to share your thoughts on )59.5 49.15 ms
re sp
%%PageTrailer
%%Page: 7 7
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(glance.txt                                                Page 7)59.5 790.15 ms
F0 sf
(the competition in the comment section.)59.5 764.15 ms
(And check my other blog post: https://medium.com/@PABTennnis/how)59.5 738.15 ms
(-to-create-a-neural-network-from-scratch-in-python-math-code-fd8)59.5 725.15 ms
(74168e955)59.5 712.15 ms
(Kaggle: https://www.kaggle.com/rftexas)59.5 686.15 ms
re sp
%%PageTrailer
%%Trailer
%%Pages: 7
%%EOF
