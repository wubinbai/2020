https://blog.csdn.net/Filwl_/article/details/80961445



    首页
    博客
    学院
    下载
    论坛
    问答
    活动
    专题
    招聘
    APP
    VIP会员
    博客之星

    写博客
    登录/注册

用 Keras 建立CNN对 UrbanSound 进行音频分类
原创 jinnsjj 最后发布于2018-07-08 18:40:56 阅读数 2839 收藏
展开
Urban Sound Classifier using CNN v2

更好的格式化阅读请参考我的jupyter lab 输出→https://jinnsjj.github.io/projects/src/USC_CNN_v2.html

第一个CNN的分类器效果惨烈，有许多细节都没有注意到，感觉修改也令人心烦，从头开始。老实说我也不知道这次能不能成功，边做边看吧。
上次踩过的坑和经验

    之前把频谱当作训练数据输入，但频谱里的数值都是负数，后来换为了绝对值。但这样其实也不行，应该要进行normalization。把是把值的范围限制在[-1,1]还是[0,1]还不清楚。我的想法是根据relu的性质，应当是[0,1]。（结果：应当时-1到1，值是*w+b再激活，所以负数不影响）
    计算mfcc时的维度一般是40，有用的一般是2到13维。

构想

首先明确一下这次要做的事情：

    训练集：UrbanSound8K dataset，训练用fold 1-3，validation用从整个数据集里面随意找一些样本，test用fold 10。
    输入：MFCC，normalization为mean=0, var=1。
    网络：一个非常简单的CNN，两层conv2D层，进入一个全连接层。
    输出：10个class

动手，去做

# draw
%matplotlib inline
import matplotlib.pyplot as plt
plt.style.use('ggplot')
# basic handling
import os
import glob
import pickle
import numpy as np
# audio
import librosa
import librosa.display
import IPython.display
# normalization
import sklearn
# nn
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import to_categorical
from keras.callbacks import LearningRateScheduler
keras.__version__

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23

Using TensorFlow backend.

'2.2.0'

    1
    2
    3

指定dataset的位置

parent_dir = '../data/UrbanSound8K/audio/'

train_dir = 'train/'
val_dir = 'val/'
test_dir = 'fold10/'

file_name = '*.wav'

train_files = glob.glob(os.path.join(parent_dir, train_dir, file_name))
val_files = glob.glob(os.path.join(parent_dir, val_dir, file_name))
test_files = glob.glob(os.path.join(parent_dir, test_dir, file_name))

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

定义一个函数用于读取音频片段，库里的片段几乎都是4s，但有一部分小于4秒，将它们补零。采样率22050，4秒一共88200个采样点。

def load_clip(filename):
    x, sr = librosa.load(filename)
    x = np.pad(x,(0,88200-x.shape[0]),'constant')
    return x, sr

    1
    2
    3
    4

    1
    2
    3
    4

再定义一个函数，用于提取片段的mfcc并进行normalization。

def extract_feature(filename):
    x, sr = load_clip(filename)
    mfccs = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=40)
    norm_mfccs = sklearn.preprocessing.scale(mfccs, axis=1)
    return norm_mfccs

    1
    2
    3
    4
    5

    1
    2
    3
    4
    5

# 测试extract_feature是否正常工作
mfccs = extract_feature('./1.wav')
plt.figure(figsize=(20,5))
librosa.display.specshow(mfccs, sr=22050, x_axis='time', cmap='viridis')
plt.colorbar()
plt.show()
print (mfccs.var(axis=1))
print (mfccs.mean(axis=1))

    1
    2
    3
    4
    5
    6
    7
    8

    1
    2
    3
    4
    5
    6
    7
    8

这里写图片描述

[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
[-1.25692648e-14  1.57869864e-16  5.60887239e-16  4.24836787e-16
  1.40542683e-16  6.23778486e-16  4.52431926e-17  4.46014452e-17
 -4.88530218e-17 -4.99921235e-16 -3.52640203e-16 -4.04300870e-17
 -6.48164887e-17 -5.00562982e-17 -1.41505305e-16  1.22573756e-16
  1.66854327e-17 -4.73609591e-16 -1.86748497e-16 -4.96712498e-16
 -7.89349318e-17 -2.19477615e-16 -3.76063984e-16 -8.41972606e-16
  0.00000000e+00 -2.95203810e-16 -3.54244572e-16  2.27820332e-16
  2.80443620e-16 -2.25253342e-16 -2.65041682e-16 -4.06867860e-16
 -1.21932008e-16  3.97883396e-17  5.10830941e-16  1.84823255e-16
  3.38842634e-16 -8.98446378e-18  3.70930005e-16 -1.42147052e-16]

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12

读取整个数据集，从整个数据集提取特征与标签

def load_dataset(filenames):
    features, labels = np.empty((0,40,173)), np.empty(0)
    cnt = 0;
    cnt_all = len(filenames)
    
    for filename in filenames:
        mfccs = extract_feature(filename)
        features = np.append(features,mfccs[None],axis=0)
        cnt+=1
        if(cnt%100==0):
            print([str(cnt)+' / '+str(cnt_all)+' finished'])
        labels = np.append(labels, filename.split('\\')[1].split('-')[1])
    return np.array(features), np.array(labels, dtype=np.int)

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13

将训练过程可视化的函数

def show_history(history):
    print(history.history.keys())
    fig = plt.figure(figsize=(20,5))
    plt.subplot(121)
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.subplot(122)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='lower left')
    plt.show()

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18

如果还没有将音频转换为features，则进行转化并保存。

# train_x, train_y = load_dataset(train_files)
# pickle.dump(train_x, open('./train_x.dat', 'wb'))
# pickle.dump(train_y, open('./train_y.dat', 'wb'))

# val_x, val_y = load_dataset(val_files)
# pickle.dump(val_x, open('./val_x.dat', 'wb'))
# pickle.dump(val_y, open('./val_y.dat', 'wb'))

# test_x, test_y = load_dataset(test_files)
# pickle.dump(test_x, open('./test_x.dat', 'wb'))
# pickle.dump(test_y, open('./test_y.dat', 'wb'))

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

如果已经有features了，就从文件中读取。

train_x = pickle.load(open('./train_x.dat', 'rb'))
train_y = pickle.load(open('./train_y.dat', 'rb'))
val_x = pickle.load(open('./val_x.dat', 'rb'))
val_y = pickle.load(open('./val_y.dat', 'rb'))
test_x = pickle.load(open('./test_x.dat', 'rb'))
test_y = pickle.load(open('./test_y.dat', 'rb'))

    1
    2
    3
    4
    5
    6

    1
    2
    3
    4
    5
    6

接下来对feature进行一些预处理。mfcc是二维数据，要输入conv2D层，要把它变为3维数据。因为是聚类，所以把label转化为categories

train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)
val_x = val_x.reshape(val_x.shape[0],val_x.shape[1],val_x.shape[2],1)
test_x = test_x.reshape(test_x.shape[0],test_x.shape[1],test_x.shape[2],1)

    1
    2
    3

    1
    2
    3

train_y = to_categorical(train_y)
val_y = to_categorical(val_y)
test_y = to_categorical(test_y)

    1
    2
    3

    1
    2
    3

Pre-processing至此结束，检查一下我们的训练集

print(train_x.shape)
print(train_y.shape)

    1
    2

    1
    2

(2686, 40, 173, 1)
(2686, 10)

    1
    2

没有问题的话就开始搭建模型

model = Sequential()

model.add(Convolution2D(32, (3, 3), activation='relu',input_shape = train_x.shape[1:]))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.5)) 
model.add(Convolution2D(32, (3, 3),  activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.5))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='Adam',
                loss='categorical_crossentropy',
                metrics=['accuracy'])
model.summary(line_length=80)

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14

________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
conv2d_1 (Conv2D)                   (None, 38, 171, 32)             320         
________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)      (None, 19, 85, 32)              0           
________________________________________________________________________________
dropout_1 (Dropout)                 (None, 19, 85, 32)              0           
________________________________________________________________________________
conv2d_2 (Conv2D)                   (None, 17, 83, 32)              9248        
________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)      (None, 8, 41, 32)               0           
________________________________________________________________________________
dropout_2 (Dropout)                 (None, 8, 41, 32)               0           
________________________________________________________________________________
flatten_1 (Flatten)                 (None, 10496)                   0           
________________________________________________________________________________
dense_1 (Dense)                     (None, 10)                      104970      
================================================================================
Total params: 114,538
Trainable params: 114,538
Non-trainable params: 0
________________________________________________________________________________

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23

history = model.fit(train_x, train_y, epochs=10, batch_size=32, validation_data=(val_x, val_y))

    1

    1

Train on 2686 samples, validate on 83 samples
Epoch 1/10
2686/2686 [==============================] - 13s 5ms/step - loss: 2.0973 - acc: 0.2223 - val_loss: 1.8910 - val_acc: 0.3012
Epoch 2/10
2686/2686 [==============================] - 8s 3ms/step - loss: 1.5507 - acc: 0.4151 - val_loss: 1.6829 - val_acc: 0.3494
Epoch 3/10
2686/2686 [==============================] - 8s 3ms/step - loss: 1.2991 - acc: 0.5316 - val_loss: 1.4978 - val_acc: 0.4458
Epoch 4/10
2686/2686 [==============================] - 8s 3ms/step - loss: 1.1322 - acc: 0.5934 - val_loss: 1.7221 - val_acc: 0.3976
Epoch 5/10
2686/2686 [==============================] - 8s 3ms/step - loss: 1.0006 - acc: 0.6385 - val_loss: 1.7749 - val_acc: 0.4096
Epoch 6/10
2686/2686 [==============================] - 8s 3ms/step - loss: 0.9274 - acc: 0.6660 - val_loss: 1.4768 - val_acc: 0.4578
Epoch 7/10
2686/2686 [==============================] - 8s 3ms/step - loss: 0.7824 - acc: 0.7226 - val_loss: 1.4234 - val_acc: 0.4819
Epoch 8/10
2686/2686 [==============================] - 8s 3ms/step - loss: 0.7153 - acc: 0.7390 - val_loss: 1.5800 - val_acc: 0.4699
Epoch 9/10
2686/2686 [==============================] - 8s 3ms/step - loss: 0.6537 - acc: 0.7640 - val_loss: 1.6162 - val_acc: 0.5301
Epoch 10/10
2686/2686 [==============================] - 8s 3ms/step - loss: 0.5779 - acc: 0.7897 - val_loss: 1.3760 - val_acc: 0.5060

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21

show_history(history)

    1

    1

dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])

    1

这里写图片描述

1
1

1

1

    点赞 1
    收藏
    分享

jinnsjj
发布了37 篇原创文章 · 获赞 17 · 访问量 4万+
私信
关注

    weixin_43807566
    洪峰 Ford10个月前你好，想问下，如何下载8k数据集，没法翻墙，是否可以共享到百度网盘上？查看回复(5)

    1

    ww2331544645
    ww23315446451个月前测试了一下楼主的代码发现跑不通，稍微更改了下 train_y = to_categorical(train_y) val_y = to_categorical(val_y) test_y = to_categorical(test_y) 替换为 train_y = np.array(keras.utils.to_categorical(train_y, 10)) val_y = np.array(keras.utils.to_categorical(val_y, 10)) test_y = np.array(keras.utils.to_categorical(test_y, 10))

    weixin_44472278
    微日记1个月前楼主可以分享一下数据集吗？邮箱986674755@qq.com.万分感谢！！

    c2c2c2aa
    岚DEMO1年前大神，你最后的准确率是多少啊？查看回复(1)

登录 查看 10 条热评
基于CNN的狗叫，猫叫语音分类	

阅读数 1180

基于CNN的狗叫，猫叫语音分类最近开始北漂的实习生活，第一家实习单位还是挺不错的。说句题外话，北京的生活没有想象中的那么恐怖，没有想象中的那么累，反而挺有人情味的。公司里的主要业务是做“声纹识别”的，... 博文
来自： qq_21157073的博客
如何使用TensorFlow实现音频分类任务

阅读数 6704

本文介绍了一种使用 TensorFlow 将音频进行分类（包括种类、场景等）的实现方案，包括备选模型、备选数据集、数据集准备、模型训练、结果提取等都有详细的引导，特别是作者还介绍了如何实现 web 接... 博文
来自： 机器之心
语音分类任务（基于UrbanSound8K数据集）

阅读数 4358

一、代码构思二、代码实现三、完整代码四、github地址环境：win10，python3，tensorflow1.9语音方面的资料不如图像识别的多，所以特地写了一份博客（并不如何严谨），希望可以帮到大... 博文
来自： c2c2c2aa的博客
音频分类	

阅读数 125

一、音频基础一段音频包含两个最基本的信息：时间长短和采样率（帧率）。采样率即一秒钟采样多少，以KHz为单位。故总帧数=采样率*时间我们选择一段音频导入来看看其采样率时间等信息。采用python自带wa... 博文
来自： weixin_42105432的博客
Python-基于卷积神经网络的Keras音频分类器 08-11
基于卷积神经网络的Keras音频分类器
下载
基于Urbansound8K数据集的环境声识别的方法简述

阅读数 651

摘要根据城市环境声识别的要求，为了选择更优的环境声事件识别方案，我对与UrbanSound8K声音数据集相关的论文进行了搜集、比较、分析，据此来给当前面临的识别率低的问题寻找到个一个大概的解决方向。最... 博文
来自： 李芳足大大的博客
利用神经网络进行音频数据分类	

阅读数 3003

IntroductionWhenyougetstartedwithdatascience,youstartsimple.Yougothroughsimpleprojectslike LoanPredi... 博文
来自： Butertfly的博客
用keras实现cnn分类	

阅读数 310

搞了挺久，包括正确率的提高，还有各种错误之后好了import tensorflowimport kerasfrom keras.layers import Dense, Dropout, Activa... 博文
来自： weixin_43405448的博客
从入门到精通，Java学习路线导航（附学习资源）

阅读数 7万+

引言最近也有很多人来向我"请教"，他们大都是一些刚入门的新手，还不了解这个行业，也不知道从何学起，开始的时候非常迷茫，实在是每天回复很多人也很麻烦，所以在这里统一作个回复吧。Java学习路线当然，这里... 博文
来自： java_sha的博客
1. 数据集准备和工具安装

阅读数 2797

数据集和代码均已上传到Github中，欢迎大家下载使用。Github地址：https://github.com/JasonZhang156/Sound-Recognition-Tutorial如果这个... 博文
来自： z小白的博客
干货：手把手教你在音频分类DCASE2017比赛中夺冠

阅读数 2661

这是一篇旧闻了。2017-09-23 00:00无人驾驶最新消息：来自英国萨里大学的团队徐勇博士等夺得DCASE2017 challenge比赛冠军。战胜来自CMU, New York Univers... 博文
来自： sunfoot001的专栏
qq_21157073关注
qq_21157073

20篇文章

排名:千里之外

机器之心V关注
机器之心V

692篇文章

排名:2000+

岚DEMO关注
岚DEMO

15篇文章

排名:千里之外

猫老壳关注
猫老壳

83篇文章

排名:千里之外

UrbanSound8K

阅读数 360

1用 Keras 建立CNN对 UrbanSound 进行音频分类定义一个函数用于读取音频片段，库里的片段几乎都是4s，但有一部分小于4秒，将它们补零。采样率22050，4秒一共88200个采样点。d... 博文
来自： tony2278的专栏
如何使用CNN进行语音信号分析

阅读数 743

CNN对图片分类能够取得很高的准确率，而语音信号经过傅里叶变换或者其他变换能够得到时间-频率图。大家的想法都很直接，能不能用于语音信号的分析？于是就有了下面的探索。。估计看完的小伙伴应该能够实现一个C... 博文
来自： Siucaan
利用keras搭建CNN完成图片分类	

阅读数 1255

文章目录一、简介二、流程1.数据处理2.神经网络搭建3.训练三、参考一、简介本文旨在通过一些简单的案例，学习如何通过keras搭建CNN。从数据读取，数据处理，神经网络搭建，模型训练等。本文也是参考其... 博文
来自： weixin_41512727的博客
爬虫小程序 - 爬取王者荣耀全皮肤

阅读数 11万+

王者荣耀全皮肤图片爬取 博文
来自： 君莫笑
花了20分钟，给女朋友们写了一个web版群聊程序

阅读数 21万+

参考博客[1]https://www.byteslounge.com/tutorials/java-ee-html5-websocket-example 博文
详细说明用keras建立训练自己数据的LSTM----语音方向

阅读数 5484

最近在研究用keras实现一个LSTM来训练自己的数据(LSTM的基本原理请自行补习），一开始自己用的数据用DNN来训练，后来要转向LSTM,因为两者的输入是不一样的，所以有些焦头烂额，DNN的输入格... 博文
来自： u011283536的博客
Python——画一棵漂亮的樱花树（不同种樱花+玫瑰+圣诞树喔）

阅读数 15万+

最近翻到一篇知乎，上面有不少用Python（大多是turtle库）绘制的树图，感觉很漂亮，我整理了一下，挑了一些我觉得不错的代码分享给大家（这些我都测试过，确实可以生成）one 樱花树 动态生成樱花效... 博文
来自： 碎片
基于CNN+MFCC的语音情感识别

阅读数 850

个人博客：http://www.chenjianqu.com/原文链接：http://www.chenjianqu.com/show-45.html近年来，随着信息技术的飞速发展，智能设备正在逐渐地融... 博文
来自： 陈建驱的博客
史上最详细的IDEA优雅整合Maven+SSM框架（详细思路+附带源码）

阅读数 11万+

网上很多整合SSM博客文章并不能让初探ssm的同学思路完全的清晰，可以试着关掉整合教程，摇两下头骨，哈一大口气，就在万事具备的时候，开整，这个时候你可能思路全无 ~中招了咩~ ，还有一些同学依旧在使用... 博文
来自： 程序员宜春的博客
计算机考研，这样选学校才是正解

阅读数 2万+

写了一篇《启舰：对计算机专业来说学历真的重要吗？》，一时间N多同学咨询自身情况要不要考研，眼看有点Hold不住，索性又出了一篇《启舰：计算机专业有必要考研吗？》，结果，又有同学说：“我是渣渣二本，想考... 博文
来自： 启舰
进程之间究竟有哪些通信方式

阅读数 1306

有一次面试的时候，被问到进程之间有哪些通信方式，不过由于之前没深入思考且整理过，说的并不好。想必大家也都知道进程有哪些通信方式，可是我猜很多人都是靠着”背“来记忆的，所以今天的这篇文章，讲给大家详细着... 博文
来自： weixin_30680385的博客
语音识别与分类（三分类）

阅读数 3272

目的：识别三个单词（bed，cat，happy）github：https://github.com/yaokaishile/three-classification一：导入需要的包importlibr... 博文
来自： c2c2c2aa的博客
神经网络-CNN结构和语音识别应用

阅读数 1万+

一、基本结构入门介绍：https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/参考deeplearning.IanGoodfel... 博文
来自： xmdxcsj的专栏
学会了这些技术，你离BAT大厂不远了

阅读数 4万+

每一个程序员都有一个梦想，梦想着能够进入阿里、腾讯、字节跳动、百度等一线互联网公司，由于身边的环境等原因，不知道 BAT 等一线互联网公司使用哪些技术？或者该如何去学习这些技术？或者我该去哪些获取这些... 博文
自己跑caffe 反卷积实验（图像去噪）总结

阅读数 4591

1、在复原韩国Hyeonwoo Noh 的Learning Deconvolution Network for Semantic Segmentation的实验过程中，运行训练网络的指令是报错：...... 博文
来自： wonengguwozai的博客
keras实现网络流量分类功能的CNN	

阅读数 1131

数据集选用KDD99数据下载地址：http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html需求：https://blog.csdn.net/com... 博文
来自： 醉糊涂仙的博客
详解卷积神经网络（CNN）在语音识别中的应用

阅读数 768

欢迎大家前往腾讯云社区，获取更多腾讯海量技术实践干货哦~作者：侯艺馨前言总结目前语音识别的发展现状，dnn、rnn/lstm和cnn算是语音识别中几个比较主流的方向。2012年，微软邓力和俞栋老师将前... 博文
来自： weixin_34114823的博客
音频特征提取——常用音频特征

阅读数 771

作者：桂。时间：2017-05-05  21:45:07链接：http://www.cnblogs.com/xingshansi/p/6815217.html 前言主要总结一下常用的音频特征，并给出具... 博文
来自： weixin_33905756的博客
基于深度学习的语音分类识别（附代码）

阅读数 5957

音频与我们生活有着十分联系。我们的大脑不断处理和理解音频数据，并为您提供有关环境的信息。一个简单的例子就是你每天与人交谈。这个演讲被另一个人看出来进行讨论。即使你认为自己处于一个安静的环境中，你也会听... 博文
来自： python练手项目实战
对计算机专业来说学历真的重要吗？

阅读数 28万+

我本科学校是渣渣二本，研究生学校是985，现在毕业五年，校招笔试、面试，社招面试参加了两年了，就我个人的经历来说下这个问题。这篇文章很长，但绝对是精华，相信我，读完以后，你会知道学历不好的解决方案，记... 博文
来自： 启舰
利用keras搭建CNN进行mnist数据集分类	

阅读数 36

当接触深度学习算法的时候，大家都很想自己亲自实践一下这个算法，但是一想到那些复杂的程序，又感觉心里面很累啊，又要学诸如tensorflow、theano这些框架。那么，有没有什么好东西能够帮助我们快速... 博文
来自： weixin_30682415的博客
声音采样率对声音事件分类的简单探究

阅读数 931

  环境音识别简述    通过阅读国内外文献总结出声音识别的流程如下图所示。                                                              ... 博文
来自： 李芳足大大的博客
张小龙-年薪近3亿的微信之父，他是如何做到的？

阅读数 10万+

张小龙生于湖南邵东魏家桥镇，家庭主要特点：穷。不仅自己穷，亲戚也都很穷，可以说穷以类聚。爷爷做过铜匠，总的来说，标准的劳动阶级出身。家有兄弟两人，一个小龙，一个小虎。小虎好动，与邻里打成一片，小龙好静... 博文
来自： 姜兴琪的博客
程序员必须掌握的核心算法有哪些？

阅读数 19万+

由于我之前一直强调数据结构以及算法学习的重要性，所以就有一些读者经常问我，数据结构与算法应该要学习到哪个程度呢？，说实话，这个问题我不知道要怎么回答你，主要取决于你想学习到哪些程度，不过针对这个问题，... 博文
来自： 帅地
keras中7大数据集datasets介绍

阅读数 5311

keras数据集主要有以下7种（可从keras官方文档阅读：https://keras.io/datasets/），对其中部分数据集我进行了学习和实践，并写了笔记。另外加几个数据集的下载地址：dogi... 博文
来自： 山中有石为玉
使用Keras对交通标志进行分类	

阅读数 28

使用Keras对交通标志进行分类 一、概述本文主要记录的在使用Keras过程中，实现交通标志分类。文本主要使用的环境为：Python3.... 博文
音频特征提取及差异

阅读数 9701

MFCC特征提取步骤：预加重-&amp;amp;amp;amp;gt;STFT-&amp;amp;amp;amp;gt;mel滤波-&amp;amp;amp;amp;gt;DC... 博文
来自： u010592995的专栏
相见恨晚的超实用网站

阅读数 4万+

相见恨晚的超实用网站 持续更新中。。。 博文
Java学习的正确打开方式

阅读数 10万+

在博主认为，对于入门级学习java的最佳学习方法莫过于视频+博客+书籍+总结，前三者博主将淋漓尽致地挥毫于这篇博客文章中，至于总结在于个人，实际上越到后面你会发现学习的最好方式就是阅读参考官方文档其次... 博文
有哪些让程序员受益终生的建议

阅读数 12万+

从业五年多，辗转两个大厂，出过书，创过业，从技术小白成长为基层管理，联合几个业内大牛回答下这个问题，希望能帮到大家，记得帮我点赞哦。 敲黑板！！！读了这篇文章，你将知道如何才能进大厂，如何实现财务自... 博文
大学四年自学走来，这些私藏的实用工具/学习网站我贡献出来了

阅读数 24万+

大学四年，看课本是不可能一直看课本的了，对于学习，特别是自学，善于搜索网上的一些资源来辅助，还是非常有必要的，下面我就把这几年私藏的各种资源，网站贡献出来给你们。主要有：电子书搜索、实用工具、在线视频... 博文
linux系列之常用运维命令整理笔录

阅读数 15万+

本博客记录工作中需要的linux运维命令，大学时候开始接触linux，会一些基本操作，可是都没有整理起来，加上是做开发，不做运维，有些命令忘记了，所以现在整理成博客，当然vi，文件操作等就不介绍了，慢... 博文
比特币原理详解

阅读数 13万+

一、什么是比特币 比特币是一种电子货币，是一种基于密码学的货币，在2008年11月1日由中本聪发表比特币白皮书，文中提出了一种去中心化的电子记账系统，我们平时的电子现金是银行来记账，因为银行的背后是... 博文
程序员接私活怎样防止做完了不给钱？

阅读数 12万+

首先跟大家说明一点，我们做 IT 类的外包开发，是非标品开发，所以很有可能在开发过程中会有这样那样的需求修改，而这种需求修改很容易造成扯皮，进而影响到费用支付，甚至出现做完了项目收不到钱的情况。 那... 博文
网页实现一个简单的音乐播放器（大佬别看。(⊙﹏⊙)）

阅读数 2万+

今天闲着无事，就想写点东西。然后听了下歌，就打算写个播放器。 于是乎用h5 audio的加上js简单的播放器完工了。 演示地点演示 html代码如下` music ... 博文
Python十大装B语法

阅读数 22万+

Python 是一种代表简单思想的语言，其语法相对简单，很容易上手。不过，如果就此小视 Python 语法的精妙和深邃，那就大错特错了。本文精心筛选了最能展现 Python 语法之精妙的十个知识点，并... 博文
数据库优化 - SQL优化

阅读数 12万+

以实际SQL入手，带你一步一步走上SQL优化之路！ 博文
2019年11月中国大陆编程语言排行榜

阅读数 4万+

2019年11月2日，我统计了某招聘网站，获得有效程序员招聘数据9万条。针对招聘信息，提取编程语言关键字，并统计如下： 编程语言比例 rank pl_ percentage 1 jav... 博文
通俗易懂地给女朋友讲：线程池的内部原理

阅读数 7万+

餐盘在灯光的照耀下格外晶莹洁白，女朋友拿起红酒杯轻轻地抿了一小口，对我说：“经常听你说线程池，到底线程池到底是个什么原理？”... 博文
《奇巧淫技》系列-python！！每天早上八点自动发送天气预报邮件到QQ邮箱

阅读数 1万+

将代码部署服务器，每日早上定时获取到天气数据，并发送到邮箱。 也可以说是一个小型人工智障。 知识可以运用在不同地方，不一定非是天气预报。... 博文
经典算法（5）杨辉三角

阅读数 5万+

杨辉三角 是经典算法，这篇博客对它的算法思想进行了讲解，并有完整的代码实现。... 博文
英特尔不为人知的 B 面

阅读数 2万+

从 PC 时代至今，众人只知在 CPU、GPU、XPU、制程、工艺等战场中，英特尔在与同行硬件芯片制造商们的竞争中杀出重围，且在不断的成长进化中，成为全球知名的半导体公司。殊不知，在「刚硬」的背后，英... 博文
腾讯算法面试题：64匹马8个跑道需要多少轮才能选出最快的四匹？

阅读数 5万+

昨天，有网友私信我，说去阿里面试，彻底的被打击到了。问了为什么网上大量使用ThreadLocal的源码都会加上private static？他被难住了，因为他从来都没有考虑过这个问题。无独有偶，今天笔... 博文
面试官：你连RESTful都不知道我怎么敢要你？

阅读数 8万+

干货，2019 RESTful最贱实践 博文
刷了几千道算法题，这些我私藏的刷题网站都在这里了！

阅读数 6万+

遥想当年，机缘巧合入了 ACM 的坑，周边巨擘林立，从此过上了"天天被虐似死狗"的生活… 然而我是谁，我可是死狗中的战斗鸡，智力不够那刷题来凑，开始了夜以继日哼哧哼哧刷题的日子，从此"读题与提交... 博文
SQL-小白最佳入门sql查询一

阅读数 4万+

不要偷偷的查询我的个人资料，即使你再喜欢我，也不要这样，真的不好； 博文
JavaScript 为什么能活到现在？

阅读数 1万+

作者 | 司徒正美 责编 |郭芮 出品 | CSDN（ID：CSDNnews） JavaScript能发展到现在的程度已经经历不少的坎坷，早产带来的某些缺陷是永久性的，因此浏览器才有禁用Ja... 博文
项目中的if else太多了，该怎么重构？

阅读数 11万+

介绍 最近跟着公司的大佬开发了一款IM系统，类似QQ和微信哈，就是聊天软件。我们有一部分业务逻辑是这样的 if (msgType = "文本") { // dosomething } else if... 博文
致 Python 初学者

阅读数 16万+

欢迎来到“Python进阶”专栏！来到这里的每一位同学，应该大致上学习了很多 Python 的基础知识，正在努力成长的过程中。在此期间，一定遇到了很多的困惑，对未来的学习方向感到迷茫。我非常理解你们所... 博文
Python 编程开发 实用经验和技巧

阅读数 7056

Python是一门很灵活的语言，也有很多实用的方法，有时候实现一个功能可以用多种方法实现，我这里总结了一些常用的方法和技巧，包括小数保留指定位小数、判断变量的数据类型、类方法@classmethod、... 博文
吐血推荐珍藏的Visual Studio Code插件

阅读数 8038

作为一名Java工程师，由于工作需要，最近一个月一直在写NodeJS，这种经历可以说是一部辛酸史了。好在有神器Visual Studio Code陪伴，让我的这段经历没有更加困难。眼看这段经历要告一段... 博文
实战：如何通过python requests库写一个抓取小网站图片的小爬虫

阅读数 1718

有点爱好的你，偶尔应该会看点图片文字，最近小网站经常崩溃消失，不如想一个办法本地化吧，把小照片珍藏起来！ 首先，准备一个珍藏的小网站，然后就可以开始啦！ 第一步 我们先写一个获取网站的url的链接，... 博文
“狗屁不通文章生成器”登顶GitHub热榜，分分钟写出万字形式主义大作

阅读数 13万+

一、垃圾文字生成器介绍 最近在浏览GitHub的时候，发现了这样一个骨骼清奇的雷人项目，而且热度还特别高。 项目中文名：狗屁不通文章生成器 项目英文名：BullshitGenerator 根据作... 博文
程序员：我终于知道post和get的区别

阅读数 19万+

是一个老生常谈的话题，然而随着不断的学习，对于以前的认识有很多误区，所以还是需要不断地总结的，学而时习之，不亦说乎... 博文
《程序人生》系列-这个程序员只用了20行代码就拿了冠军

阅读数 5万+

你知道的越多，你不知道的越多 点赞再看，养成习惯GitHub上已经开源https://github.com/JavaFamily，有一线大厂面试点脑图，欢迎Star和完善 前言 这一期不算《吊打... 博文
加快推动区块链技术和产业创新发展，2019可信区块链峰会在京召开

阅读数 5万+

11月8日，由中国信息通信研究院、中国通信标准化协会、中国互联网协会、可信区块链推进计划联合主办，科技行者协办的2019可信区块链峰会将在北京悠唐皇冠假日酒店开幕。 　　区块链技术被认为是继蒸汽机、... 博文
Python 植物大战僵尸代码实现(2):植物卡片选择和种植

阅读数 1万+

这篇文章要介绍的是： - 上方植物卡片栏的实现。 - 点击植物卡片，鼠标切换为植物图片。 - 鼠标移动时，判断当前在哪个方格中，并显示半透明的植物作为提示。... 博文
程序员把地府后台管理系统做出来了，还有3.0版本！12月7号最新消息：已在开发中有github地址

阅读数 16万+

第一幕：缘起 听说阎王爷要做个生死簿后台管理系统，我们派去了一个程序员…… 996程序员做的梦： 第一场：团队招募 为了应对地府管理危机，阎王打算找“人”开发一套地府后台管理系统，于是... 博文
为什么要学数据结构？

阅读数 1万+

一、前言 在可视化化程序设计的今天，借助于集成开发环境可以很快地生成程序，程序设计不再是计算机专业人员的专利。很多人认为，只要掌握几种开发工具就可以成为编程高手，其实，这是一种误解。要想成为一个专业的... 博文
金山办公上市，雷军心愿了却！

阅读数 1万+

作者 | 胡巍巍 出品 | CSDN（ID：CSDNnews） 11月17日，大周末的，雷军微博发了个重磅消息： “明天将是里程碑式的一天，金山办公终于成功在科创板挂牌上市了！ 从1988年金... 博文
8年经验面试官详解 Java 面试秘诀

阅读数 8万+

作者 |胡书敏 责编 | 刘静 出品 | CSDN（ID：CSDNnews） 本人目前在一家知名外企担任架构师，而且最近八年来，在多家外企和互联网公司担任Java技术面试官，前后累计面试了有两三... 博文
面试官如何考察你的思维方式？

阅读数 4万+

1.两种思维方式在求职面试中，经常会考察这种问题：北京有多少量特斯拉汽车？某胡同口的煎饼摊一年能卖出多少个煎饼？深圳有多少个产品经理？一辆公交车里能装下多少个乒乓球？一个正常成年人有多少根头发？这类估... 博文
碎片化的时代，如何学习

阅读数 1万+

今天周末，和大家聊聊学习这件事情。 在如今这个社会，我们的时间被各类 APP 撕的粉碎。 刷知乎、刷微博、刷朋友圈； 看论坛、看博客、看公号； 等等形形色色的信息和知识获取方式一个都不错过。 貌似学了... 博文
腾讯“疯狂”开源！

阅读数 3万+

作者 | 马超 责编 | 胡巍巍 出品 | CSDN（ID：CSDNnews） 近日，腾讯自研的万亿级分布式消息中间件TubeMQ正式开源，并捐赠给Apache基金会，成为基金会官方认可的Inc... 博文
so easy！ 10行代码写个"狗屁不通"文章生成器

阅读数 8万+

前几天，GitHub 有个开源项目特别火，只要输入标题就可以生成一篇长长的文章。 背后实现代码一定很复杂吧，里面一定有很多高深莫测的机器学习等复杂算法 不过，当我看了源代码之后... 博文
知乎高赞：中国有什么拿得出手的开源软件产品？(整理自本人原创回答)

阅读数 5万+

知乎高赞：中国有什么拿得出手的开源软件产品？ 在知乎上，有个问题问“中国有什么拿得出手的开源软件产品（在 GitHub 等社区受欢迎度较好的）？” 事实上，还不少呢~ 本人于2019.7.6进行... 博文
MySQL数据库总结

阅读数 7万+

一、数据库简介 数据库(Database，DB)是按照数据结构来组织，存储和管理数据的仓库。 典型特征：数据的结构化、数据间的共享、减少数据的冗余度，数据的独立性。 关系型数据库：使用关系模型把数据... 博文
python json java mysql pycharm android linux json格式 c# 二进制截断字符串 c#实现窗体设计器 c#检测是否为微信 c# plc s1200 c#里氏转换原则 c# 主界面 c# do loop c#存为组套 模板 c# 停掉协程 c# rgb 读取图片
©️2019 CSDN 皮肤主题: 精致技术 设计师: CSDN官方博客
jinnsjj
TA的个人主页 >

原创
    37

粉丝
    23

获赞
    17

评论
    17

访问
    4万+

等级:

周排名:
    9万+ 

积分:
    816 

总排名:
    9万+ 

勋章:
关注
私信
最新文章

    Unity 读取资源文件 Resources.Load()
    音频重采样 python+librosa
    librosa.load() 读取音频的采样率处理
    impulse response 使用的踩坑 —— cconv
    语音情感识别探讨

分类专栏

    leetcode刷题之路 12篇
    学习笔记 17篇
    Acoustics 2篇
    Coding 19篇
    LeetCode 13篇
    C++ 19篇
    心得 1篇
    Audio 7篇
    C# 2篇
    Unity 2篇

展开
归档

    2018年11月 1篇
    2018年10月 3篇
    2018年9月 1篇
    2018年7月 20篇
    2018年6月 3篇
    2018年3月 1篇
    2016年1月 7篇
    2015年4月 1篇

展开
热门文章

    librosa.load() 读取音频的采样率处理

    阅读数 5937
    Unity学习日记-使用脚本进行音频资源的读取，Resources.LoadAll

    阅读数 5428
    Unity 读取资源文件 Resources.Load()

    阅读数 4541
    Unity学习日记-第二个Demo，脚本间的参数传递

    阅读数 4123
    语音情感识别探讨

    阅读数 3704

最新评论

    用 Keras 建立CNN对 Ur...

    ww2331544645：测试了一下楼主的代码发现跑不通，稍微更改了下 train_y = to_categorical(train_y) val_y = to_categorical(val_y) test_y = to_categorical(test_y) 替换为 train_y = np.array(keras.utils.to_categorical(train_y, 10)) val_y = np.array(keras.utils.to_categorical(val_y, 10)) test_y = np.array(keras.utils.to_categorical(test_y, 10))
    用 Keras 建立CNN对 Ur...

    weixin_44472278：楼主可以分享一下数据集吗？邮箱986674755@qq.com.万分感谢！！
    用 Keras 建立CNN对 Ur...

    weixin_44472278：[reply]weixin_43807566[/reply] 可以分享一下数据集吗？邮箱986674755@qq.com.万分感谢！
    Unity学习日记-Unity音频...

    qq_31310037：博主有试过卷积了吗
    用 Keras 建立CNN对 Ur...

    mlnmlndyn：[reply]mlnmlndyn[/reply] 谢谢!!

CSDN学院

CSDN学院
CSDN企业招聘

CSDN企业招聘

kefu@csdn.net

QQ客服

客服论坛

400-660-0108

工作时间 8:30-22:00

关于我们招聘广告服务 网站地图

京ICP备19004658号 经营性网站备案信息

公安备案号 11010502030143

©1999-2020 北京创新乐知网络技术有限公司

网络110报警服务

北京互联网违法和不良信息举报中心

中国互联网举报中心家长监护版权申诉
举报

