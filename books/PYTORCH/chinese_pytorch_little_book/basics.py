import torch as t

def beg():
    print('===================beg==================')
def end():
    print('===================end==================')
beg()
tensor = t.Tensor(5,3)

print('tensor = t.Tensor(5,3) ')
print(tensor)
print('tensor.size() is same as tensor.shape')
print(tensor.size())
print('tensor.dim() is the same as tensor.ndim')
print(tensor.ndim)
end()
beg()
print('x=t.rand(5,3)')
x=t.rand(5,3)
print(x)
print('c = x + tensor is the same as c = t.add(x,tensor)')
c = x + tensor
print(c)
print('there is even method 3: c = t.Tensor(5,3), t.add(x,tensor,out=c)')
print('IN PLACE add: c = t.Tensor(5,3), t.add_(x)')
end()
beg()
print('init. from numpy arr: arr=np.array([1,2,3]);ten_arr = t.from_numpy(arr)')
arr=np.array([1,2,3]);ten_arr = t.from_numpy(arr)
print(ten_arr)
print('arr_back = ten_arr.numpy()')
arr_back = ten_arr.numpy()
print(arr_back)
print('getting one element from tensor: ten_arr[0].item() ')
print(ten_arr[0].item())

end()
beg()
print('using tensor.cuda() to see availability using cuda.')
end()

beg()
print('cpu or gpu?')
print('device = t.device("cuda:0" if t.cuda.is_available() else "cpu")')
device = t.device("cuda:0" if t.cuda.is_available() else "cpu")
print('x.to(device)')
x.to(device)
end()
beg()
print('t.autograd.Variable')
print('ones = t.ones(2, 2, requires_grad=True)')
ones = t.ones(2, 2, requires_grad=True)
print(ones)

